<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>What is Artificial Intelligence (AI)? Tutorial, Meaning </title>
<link rel="stylesheet" type="text/css" href="style.css" async="">
          </style><meta http-equiv="origin-trial" content="As0hBNJ8h++fNYlkq8cTye2qDLyom8NddByiVytXGGD0YVE+2CEuTCpqXMDxdhOMILKoaiaYifwEvCRlJ/9GcQ8AAAB8eyJvcmlnaW4iOiJodHRwczovL2RvdWJsZWNsaWNrLm5ldDo0NDMiLCJmZWF0dXJlIjoiV2ViVmlld1hSZXF1ZXN0ZWRXaXRoRGVwcmVjYXRpb24iLCJleHBpcnkiOjE3MTk1MzI3OTksImlzU3ViZG9tYWluIjp0cnVlfQ=="><meta http-equiv="origin-trial" content="AgRYsXo24ypxC89CJanC+JgEmraCCBebKl8ZmG7Tj5oJNx0cmH0NtNRZs3NB5ubhpbX/bIt7l2zJOSyO64NGmwMAAACCeyJvcmlnaW4iOiJodHRwczovL2dvb2dsZXN5bmRpY2F0aW9uLmNvbTo0NDMiLCJmZWF0dXJlIjoiV2ViVmlld1hSZXF1ZXN0ZWRXaXRoRGVwcmVjYXRpb24iLCJleHBpcnkiOjE3MTk1MzI3OTksImlzU3ViZG9tYWluIjp0cnVlfQ=="><meta http-equiv="origin-trial" content="A/ERL66fN363FkXxgDc6F1+ucRUkAhjEca9W3la6xaLnD2Y1lABsqmdaJmPNaUKPKVBRpyMKEhXYl7rSvrQw+AkAAACNeyJvcmlnaW4iOiJodHRwczovL2RvdWJsZWNsaWNrLm5ldDo0NDMiLCJmZWF0dXJlIjoiRmxlZGdlQmlkZGluZ0FuZEF1Y3Rpb25TZXJ2ZXIiLCJleHBpcnkiOjE3MTkzNTk5OTksImlzU3ViZG9tYWluIjp0cnVlLCJpc1RoaXJkUGFydHkiOnRydWV9"><meta http-equiv="origin-trial" content="A6OdGH3fVf4eKRDbXb4thXA4InNqDJDRhZ8U533U/roYjp4Yau0T3YSuc63vmAs/8ga1cD0E3A7LEq6AXk1uXgsAAACTeyJvcmlnaW4iOiJodHRwczovL2dvb2dsZXN5bmRpY2F0aW9uLmNvbTo0NDMiLCJmZWF0dXJlIjoiRmxlZGdlQmlkZGluZ0FuZEF1Y3Rpb25TZXJ2ZXIiLCJleHBpcnkiOjE3MTkzNTk5OTksImlzU3ViZG9tYWluIjp0cnVlLCJpc1RoaXJkUGFydHkiOnRydWV9"><script src="https://securepubads.g.doubleclick.net/pagead/managed/js/gpt/m202311090101/pubads_impl.js" async=""></script><script src="https://config.aps.amazon-adsystem.com/configs/2e7e1587-d92f-46dd-8721-80b53eccb87e" type="text/javascript" async="async"></script><style type="text/css">.vjs-youtube .vjs-iframe-blocker { display: none; }.vjs-youtube.vjs-user-inactive .vjs-iframe-blocker { display: block; }.vjs-youtube .vjs-poster { background-size: cover; }.vjs-youtube-mobile .vjs-big-play-button { display: none; }</style><style type="text/css">
       *,
*::before,
*::after {
	box-sizing: border-box;
}

* {
	margin: 0;
	padding: 0;
}

body {
	line-height: 1.5;
	font-family: 'Poppins', sans-serif;
}

.footer {
	background-color: #151515;
	padding: 80px 0;
}

.container {
	max-width: 1170px;
	margin: auto;
}

.row {
	display: flex;
	flex-wrap: wrap;
}

ul {
	list-style: none;
}

.footer-col {
	width: 25%;
	padding: 0 15px;
}

.footer-col h4 {
	font-size: 18px;
	color: #FFF;
	text-transform: capitalize;
	margin-bottom: 35px;
	font-weight: 500;
	position: relative;
}

.footer-col h4::before {
	content: "";
	position: absolute;
	left: 0;
	bottom: -10px;
	background-color: #E91E63;
	width: 50px;
	height: 2px;
}

.footer-col ul li:not(:last-child) {
	margin-bottom: 10px;
}

.footer-col ul li a {
	color: #DDD;
	display: block;
	font-size: 1rem;
	font-weight: 300;
	text-transform: capitalize;
	text-decoration: none;
	transition: all 0.3s ease;
}

.footer-col ul li a:hover {
	color: #FFF;
	padding-left: 7px;
}

.footer-col .social-links a {
	color: #FFF;
	background-color: rgba(255, 255, 255, 0.2);
	display: inline;
	height: 100px;
	width: 100px;
	border-radius: 100%;
	text-align: center;
	margin: 0 10px 10px 0;
	line-height: 100px;
	transition: all 0.5s ease;
}

.footer-col .social-links a:hover {
	color: #151515;
	background-color: #FFF;
}

@media(max-width: 767px) {
	.footer-col {
		width: 50%;
		margin-bottom: 30px;
	}
}

@media(max-width: 574px) {
	.footer-col {
		width: 100%;
	}
}
body {
  background-image: url(photo/aaa.jpg);
  background-size: cover;
  background-position: center;
  background-repeat: no-repeat;
}

header {
  position: relative;
  background: transparent;
  padding: 1rem 0;
  z-index: 999;
}

.header-container {
  display: flex;
  align-items: center;
  justify-content: space-between;
  width: min(90%, 800px);
  margin-inline: auto;
  color: #000;
}

nav ul {
  display: flex;
  list-style: none;
  gap: 2rem;
}

nav a {
  text-decoration: none;
  color: #000;
}

nav a:hover {
  color: #4FC3F7;
}

.hamburger {
  display: none;
  cursor: pointer;
}

@media (max-width: 600px) {
  
  .toggle {
    transition: ease-in-out 550ms;
    transform: translate(0px);
    opacity: 1;
    display: block;
  }
  
  .header-container {
    width: 100%;
    padding: 0 1rem;
  }
  
  nav ul {
    flex-direction: column;
    position: absolute;
    top: 100%;
    left: 0;
    width: 100%;
    background: hsla(0, 0%, 0%, .5);
    backdrop-filter: blur(10px);
    transform: translateX(-500px);
    opacity: 0;
  }
  
  nav li {
    padding: 1rem;
    cursor: pointer;
  }
  
  nav li:hover {
    background: hsla(0, 0%, 0%, .7);
  }
  
  .hamburger {
    display: block; 
  }
}
div.onlycontent {
    margin-left: 10px;
    margin-top: 15px;
    margin-right: 4px;
    width: 58%;
    float: left;
    padding: 10px 15px;
    background :none;
  }
  #city td {
    color: black;
    line-height: 1.7;
  }
  #city li {
    line-height: 25px;
    color: black;
    margin-top: 4px;
  }
      </style>
     <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha512-z3gLpd7yknf1YoNbCzqRKc4qyor8gaKU1qmn+CShxbuBusANI9QpRohGBreCFkKxLhei6S9CQXFEbbKuqLg0DA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
     <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" integrity="sha512-W/zrbCncQnky/EzL+/AYwTtosvrM+YG/V6piQLSe2HuKS6cmbw89kjYkp3tWFn1dkWV7L1ruvJyKbLz73Vlgfg==" crossorigin="anonymous" referrerpolicy="no-referrer" />
     
     <body>
      <header>
        <div class="header-container">
          <span><img src="photo/logo1.png" style="height: 50px;width: 70px;overflow: hidden;backface-visibility: hidden;"></span>
          <nav id="nav">
            <b><i><ul id="nav-ul">
              <li><a href="nigam1.html">Home</a></li>
              <li><a href="about.html">About</a></li>
              <li><a href="AIservices.html">Service</a></li>
              <li><a href="contact.html">Contact</a></li>
            </ul></i></b>
          </nav>
          <span class="hamburger" id="button"><i class="fa-solid fa-bars"></i></span>
        </div>
      </header>
    </body>
    
    </div>
    </div>
   
    <div class="mobilemenu" style="clear:both">
    
    </div>
    <div id="menu">
    <div class="leftmenu2">
    <h2 class="spanh2"><span class="spanh2">Artificial Intelligence</span></h2>
    </div>
    <div class="leftmenu">
    <a href="nigam1.html" style="color: black;"><strong>Artificial Intelligence (AI)</strong> </a>
    <a href="nigam2.html">Applications of AI</a>
    <a href="nigam3.html">History of AI</a>
    <a href="nigam4.html">Types of AI</a>
    </div>
    <div class="leftmenu2">
    <h2 class="spanh2"><span class="spanh2">Intelligent Agent</span></h2>
    </div>
    <div class="leftmenu">
    <a href="nigam5.html">Types of Agents</a>
    <a href="nigam6.html">Intelligent Agent</a>
    <a href="nigam7.html">Agent Environment</a>
    <a href="nigam8.html">Turing Test in AI</a>
    </div>
    <div class="leftmenu2">
    <h2 class="spanh2"><span class="spanh2">Problem-solving</span></h2>
    </div>
    <div class="leftmenu">
    <a href="nigam9.html">Search Algorithms</a>
    <a href="nigam10.html">Uninformed Search Algorithm</a>
    <a href="nigam11.html">Informed Search Algorithms</a>
    <a href="nigam12.html">Hill Climbing Algorithm</a>
    <a href="nigam13.html">Means-Ends Analysis</a>
    </div>
    <div class="leftmenu2">
    <h2 class="spanh2"><span class="spanh2">Adversarial Search</span></h2>
    </div>
    <div class="leftmenu">
    <a href="nigam14.html">Adversarial search</a>
    <a href="nigam15.html">Minimax Algorithm</a>
    <a href="nigam16.html">Alpha-Beta Pruning</a>
    </div>
    <div class="leftmenu2">
    <h2 class="spanh2"><span class="spanh2">Knowledge Represent</span></h2>
    </div>
    <div class="leftmenu">
    <a href="nigam17.html">Knowledge Based Agent</a>
    <a href="nigam18.html">Knowledge Representation</a>
    <a href="nigam19.html">Knowledge Representation Techniques</a>
    <a href="nigam20.html">Propositional Logic</a>
    <a href="nigam21.html">Rules of Inference</a>
    <a href="nigam22.html">The Wumpus world</a>
    <a href="nigam23.html">knowledge-base for Wumpus World</a>
    <a href="nigam24.html">First-order logic</a>
    <a href="nigam25.html">Knowledge Engineering in FOL</a>
    <a href="nigam26.html">Inference in First-Order Logic</a>
    <a href="nigam27.html">Unification in FOL</a>
    <a href="nigam28.html">Resolution in FOL</a>
    <a href="nigam29.html">Forward Chaining and backward chaining</a>
    <a href="nigam30.html">Backward Chaining vs Forward Chaining</a>
    <a href="nigam31.html">Reasoning in AI</a>
    <a href="nigam32.html">Inductive vs. Deductive reasoning</a>
    </div>
    <div class="leftmenu2">
    <h2 class="spanh2"><span class="spanh2">Uncertain Knowledge R.</span></h2>
    </div>
    <div class="leftmenu">
    <a href="nigam33.html">Probabilistic Reasoning in AI</a>
    <a href="nigam34.html">Bayes theorem in AI</a>
    <a href="nigam35.html">Bayesian Belief Network</a>
    </div>
    <div class="leftmenu2">
    <h2 class="spanh2"><span class="spanh2">Misc</span></h2>
    </div>
    <div class="leftmenu">
    <a href="nigam36.html">Examples of AI</a>
    <a href="nigam37.html">AI Essay</a>
    <a href="nigam38.html">AI in Healthcare</a>
    <a href="nigam39.html">Artificial Intelligence in Education</a>
    <a href="nigam40.html">Artificial Intelligence in Agriculture</a>
    <a href="nigam41.html">Engineering Applications of AI</a>
    <a href="nigam42.html">Advantages &amp; Disadvantages of AI</a>
    <a href="nigam43.html">Robotics and AI</a>
    <a href="nigam44.html">Future of AI</a>
    <a href="nigam45.html">Languages used in AI</a>
    <a href="nigam46.html">Approaches to AI Learning</a>
    <a href="nigam47.html">Scope of AI</a>
    <a href="nigam48.html">Agents in AI</a>
    <a href="nigam49.html">Artificial Intelligence Jobs</a>
    <a href="nigam50.html">Amazon CloudFront</a>
    <a href="nigam51.html">Goals of Artificial Intelligence</a>
    <a href="nigam52.html">Can Artificial Intelligence replace Human Intelligence</a>
    <a href="nigam53.html">Importance of Artificial Intelligence</a>
    <a href="nigam54.html">Artificial Intelligence Stock in India</a>
    <a href="nigam55.html">How to Use Artificial Intelligence in Marketing</a>
    <a href="nigam56.html">Artificial Intelligence in Business</a>
    <a href="nigam57.html">Companies Working on Artificial Intelligence</a>
    <a href="nigam58.html">Artificial Intelligence Future Ideas</a>
    <a href="nigam59.html">Government Jobs in Artificial Intelligence in India</a>
    <a href="nigam60.html">What is the Role of Planning in Artificial Intelligence</a>
    <a href="nigam61.html">AI as a Service</a>
    <a href="nigam62.html">AI in Banking</a>
    <a href="nigam63.html">AI Tools</a>
    <a href="nigam64.html">Cognitive AI</a>
    <a href="nigam65.html">Introduction of Seaborn</a>
    <a href="nigam66.html">Natural Language ToolKit (NLTK)</a>
    <a href="nigam67.html">Best books for ML</a>
    <a href="nigam68.html">AI companies of India will lead in 2022</a>
    <a href="nigam69.html">Constraint Satisfaction Problems in Artificial Intelligence</a>
    <a href="nigam70.html">How artificial intelligence will change the future</a>
    <a href="nigam71.html">Problem Solving Techniques in AI</a>
    <a href="nigam72.html">AI in Manufacturing Industry</a>
    <a href="nigam73.html">Artificial Intelligence in Automotive Industry</a>
    <a href="nigam74.html">Artificial Intelligence in Civil Engineering</a>
    <a href="nigam75.html">Artificial Intelligence in Gaming Industry</a>
    <a href="nigam76.html">Artificial Intelligence in HR</a>
    <a href="nigam77.html">Artificial Intelligence in Medicine</a>
    <a href="nigam78.html">PhD in Artificial Intelligence</a>
    <a href="nigam79.html">Activation Functions in Neural Networks</a>
    <a href="nigam80.html">Boston Housing Kaggle Challenge with Linear Regression</a>
    <a href="nigam81.html">What are OpenAI and ChatGPT</a>
    <a href="nigam82.html">Chatbot vs. Conversational AI</a>
    <a href="nigam83.html">Iterative Deepening A* Algorithm (IDA*)</a>
    <a href="nigam84.html">Iterative Deepening Search (IDS) or Iterative Deepening Depth First Search (IDDFS)</a>
    </div>
    <div class="leftmenu2">
    <h2 class="spanh2"><span class="spanh2">Subsets of AI</span></h2>
    </div>
    <div class="leftmenu">
    <a href="nigam85.html">Subsets of AI</a>
    <a href="nigam86.html">Expert Systems</a>
    <a href="nigam87.html">Machine Learning Tutorial</a>
    <a href="nigam88.html">NLP Tutorial</a>
    </div>
    <div class="leftmenu2">
    <h2 class="spanh2"><span class="spanh2">Artificial Intelligence MCQ</span></h2>
    </div>
    <div class="leftmenu">
    <a href="nigam89.html">Artificial Intelligence MCQ</a>
    </div>
    <div class="leftmenu2">
    <h2 class="spanh2"><span class="spanh2">Related Tutorials</span></h2>
    </div>
    <div class="leftmenu"> 
    <a href="nigam92.html">Data Science Tutorial</a>
    <a href="nigam93.html">Reinforcement Learning</a>
    </div> 
</div>
</div>
<div class="onlycontent">
  <div class="onlycontentad">
  </div>
  <div class="onlycontentinner">
  <div id="city">
  <table>
  <tbody><tr><td>
  
  <b><i><h1 class="h1">Activation Functions in Neural Networks</h1>
  <p>A paradigm for information processing that draws inspiration from the brain is called an artificial neural network (ANN). ANNs learn via imitation just like people do. Through a learning process, an ANN is tailored for a particular purpose, including such pattern classification or data classification. The synapses interconnections that exist between both the neurons change because of learning.</p>
  <p>What input layer to employ with in hidden layer and at the input level of the network is one of the decisions you get to make while creating a neural network. This article discusses a few of the alternatives.</p>
  <p>The nerve impulse in neurology serves as a model for activation functions within computer science. A chain reaction permits a neuron to "fire" and send a signal to nearby neurons if the induced voltage between its interior and exterior exceeds a threshold value known as the action potential. The next series of activations, known as a "spike train," enables motor neurons to transfer commands from of the brain to the limbs and sensory neurons too transmit sensation from the digits to the brain.</p>
  <h2 class="h2">Neural Network Components</h2>
  
  <h3 class="h3">Input Layer</h3>
  <p>The input layer is first. The data will be accepted by this layer and forwarded to the remainder of the network. This layer allows feature input. It feeds the network with data from the outside world; no calculation is done here; instead, nodes simply transmit the information (features) to the hidden units.</p>
  <h3 class="h3">Hidden Layer</h3>
  <p>Since they are a component of the abstraction that any neural network provides, the nodes in this layer are not visible to the outside world. Any features entered through to the input layer are processed by the hidden layer in any way, with the results being sent to the output layer. The concealed layer is the name given to the second kind of layer. For a neural network, either there are one or many hidden layers. The number inside the example above is 1. In reality, hidden layers are what give neural networks their exceptional performance and intricacy. They carry out several tasks concurrently, including data transformation and automatic feature generation.</p>
  <h3 class="h3">Output Layer</h3>
  <p>This layer raises the knowledge that the network has acquired to the outside world. The output layer is the final kind of layer The output layer contains the answer to the issue. We receive output from the output layer after passing raw photos to the input layer.</p>
  <p>Data science makes extensive use of the rectified unit (ReLU) functional or the category of sigmoid processes, which also includes the logistic regression model, logistic hyperbolic tangent, and arctangent function.</p>
  <h2 class="h2">Activation Function</h2>
  <h3 class="h3">Definition</h3>
  <p>In artificial neural networks, an activation function is one that outputs a smaller value for tiny inputs and a higher value if its inputs are greater than a threshold. An activation function "fires" if the inputs are big enough; otherwise, nothing happens. An activation function, then, is a gate that verifies how an incoming value is higher than a threshold value.</p>
  <p>Because they introduce non-linearities in neural networks and enable the neural networks can learn powerful operations, activation functions are helpful. A feedforward neural network might be refactored into a straightforward linear function or matrix transformation on to its input if indeed the activation functions were taken out.</p>
  <p>By generating a weighted total and then including bias with it, the activation function determines whether a neuron should be turned on. The activation function seeks to boost a neuron's output's nonlinearity.</p>
  <p><strong>Explanation</strong>: As we are aware, neurons in neural networks operate in accordance with weight, bias, and their corresponding activation functions. Based on the mistake, the values of the neurons inside a neural network would be modified. This process is known as back-propagation. Back-propagation is made possible by activation functions since they provide the gradients and error required to change the biases and weights.</p>
  <h2 class="h2">Need of Non-linear Activation Functions</h2>
  <p>An interconnected regression model without an activation function is all that a neural network is. Input is transformed nonlinearly by the activation function, allowing the system to learn and perform more challenging tasks.</p>
  <p>It is merely a thing procedure that is used to obtain a node's output. It also goes by the name Transfer Function.</p>
  <p>The mixture of two linear functions yields a linear function, so no matter how several hidden layers we add to a neural network, they all will behave in the same way. The neuron cannot learn if all it has is a linear model. It will be able to learn based on the difference with respect to error with a non-linear activation function.</p>
  <p>The mixture of two linear functions yields a linear function in itself, so no matter how several hidden layers we add to a neural network, they all will behave in the same way. The neuron cannot learn if all it has is a linear model.</p>
  <p>The two main categories of activation functions are:</p>
  <ul class="points">
  <li>Linear Activation Function</li>
  <li>Non-linear Activation Functions</li>
  </ul>
  <h3 class="h3">Linear Activation Function</h3>
  <p>As can be observed, the functional is linear or linear. Therefore, no region will be employed to restrict the functions' output.</p>
  <img src="https://static.javatpoint.com/tutorial/ai/images/activation-functions-in-neural-networks.png" alt="Activation Functions in Neural Networks">
  <p>The normal data input to neural networks is unaffected by the complexity or other factors.</p>
  <h3 class="h3">Non-linear Activation Function</h3>
  <p>The normal data input to neural networks is unaffected by the complexity or other factors.</p>
  <h2 class="h2">Activation Function</h2>
  <ul class="points">
  <li><strong>Linear Function</strong></li>
  </ul>
  <p>Equation: A linear function's equation, which is y = x, is similar to the eqn of a single direction.</p>
  <p>The ultimate activation function of the last layer is nothing more than a linear function of input from the first layer, regardless of how many levels we have if they are all linear in nature. -inf to +inf is the range.</p>
  <p>Uses: The output layer is the only location where the activation function's function is applied.</p>
  <p>If we separate a linear function to add non-linearity, the outcome will no longer depend on the input "x," the function will become fixed, and our algorithm won't exhibit any novel behaviour.</p>
  <p>A good example of a regression problem is determining the cost of a house. We can use linear activation at the output layer since the price of a house may have any huge or little value. The neural network's hidden layers must perform some sort of non-linear function even in this circumstance.</p>
  <ul class="points">
  <li><strong>Sigmoid Function</strong></li>
  </ul>
  <p>It is a functional that is graphed in a "S" shape.</p>
  <p>A is equal to 1/(1 + e-x).</p>
  <p>Non-linear in nature. Observe that while Y values are fairly steep, X values range from -2 to 2. To put it another way, small changes in x also would cause significant shifts in the value of Y. spans from 0 to 1.</p>
  <p>Uses: Sigmoid function is typically employed in the output nodes of a classi?cation, where the result may only be either 0 or 1. Since the value for the sigmoid function only ranges from 0 to 1, the result can be easily anticipated to be 1 if the value is more than 0.5 and 0 if it is not.</p>
  <ul class="points">
  <li><strong>Tanh Function</strong></li>
  </ul>
  <p>The activation that consistently outperforms sigmoid function is known as tangent hyperbolic function. It's actually a sigmoid function that has been mathematically adjusted. Both are comparable to and derivable from one another.</p>
  <img src="https://static.javatpoint.com/tutorial/ai/images/activation-functions-in-neural-networks2.png" alt="Activation Functions in Neural Networks">
  <p>Range of values: -1 to +1. non-linear nature</p>
  <p>Uses: - Since its values typically range from -1 to 1, the mean again for hidden layer of a neural network will be 0 or very near to it. This helps to centre the data by getting the mean close to 0. This greatly facilitates learning for the following layer.</p>
  <p><strong>Equation:</strong></p>
  <p>max A(x) (0, x). If x is positive, it outputs x; if not, it outputs 0.</p>
  <p>Value Interval: [0, inf]</p>
  <p>Nature: non-linear, which allows us to simply backpropagate the mistakes and have the ReLU function activate many layers of neurons.</p>
  <p>Uses: Because ReLu includes simpler mathematical processes than tanh and sigmoid, it requires less computer time to run. The system is sparse and efficient for computation since only a limited number of neurons are activated at any given time.</p>
  <p>Simply said, RELU picks up information considerably more quickly than sigmoid and Tanh functions.</p>
  <ul class="points">
  <li><strong>ReLU (Rectified Linear Unit) Activation Function</strong></li>
  </ul>
  <p>Currently, the ReLU is the activation function that is employed the most globally. Since practically all convolutional neural networks and deep learning systems employ it.</p>
  <p>The derivative and the function are both monotonic.</p>
  <p>However, the problem is that all negative values instantly become zero, which reduces the model's capacity to effectively fit or learn from the data. This means that any negative input to a ReLU activation function immediately becomes zero in the graph, which has an impact on the final graph by improperly mapping the negative values.</p>
  <ul class="points">
  <li><strong>Softmax Function</strong></li>
  </ul>
  <p>Although it is a subclass of the sigmoid function, the softmax function comes in handy when dealing with multiclass classification issues.</p>
  <p>Used frequently when managing several classes. In the output nodes of image classification issues, the softmax was typically present. The softmax function would split by the sum of the outputs and squeeze all outputs for each category between 0 and 1.</p>
  <p>The output unit of the classifier, where we are actually attempting to obtain the probabilities to determine the class of each input, is where the softmax function is best applied.</p>
  <p>The usual rule of thumb is to utilise RELU, which is a usual perceptron in hidden layers and is employed in the majority of cases these days, if we really are unsure of what encoder to apply.</p>
  <p>A very logical choice for the output layer is the sigmoid function if your input is for binary classification. If our output involves multiple classes, Softmax can be quite helpful in predicting the odds for each class.</p>
  <hr><h3 class="h3">Feedback</h3>
  <ul class="points">
  <li>Send your Feedback to nigammishra826@gmail.com</li>
  </ul></i></b>
  <div class="nexttopicdiv">
  <span class="nexttopictext">Next Topic</span><span class="nexttopiclink"><a href="nigam80.html">Boston Housing Kaggle Challenge with Linear Regression</a></span>
  </div>
  
  <br><br>
  <div id="bottomnext">
  <a style="float:left" class="next" href="nigam78.html">← prev</a>
  <a style="float:right" class="next" href="nigam80.html">next →</a>
  </div>
  <br><br>
  </td></tr>
  </tbody></table>
  <head>
    <script src="https://kit.fontawesome.com/3b161c540c.js" crossorigin="anonymous"></script>
  </head>
  
  <body>
    <footer class="footer">
      <div class="container row">
        <div class="footer-col">
          <h4>About</h4>
          <ul>
            <li><a href="nigam1.html">Artificial intelligence(AI)</a></li>
            <li><a href="nigam4.html">Types of AI</a></li>
            <li><a href="nigam8.html">Turing test of AI</a></li>
            <li><a href="nigam22.html">The Wumpus world</a></li>
          </ul>
        </div>
        <div class="footer-col">
          <h4>get help</h4>
          <ul>
            <li><a href="nigam89.html">MCQ</a></li>
            <li><a href="nigam87.html">Machine Learning</a></li>
            <li><a href="nigam88.html">NPL</a></li>
            <li><a href="nigam92.html">Data Science</a></li>
            <li><a href="nigam93.html">Reinforcement learning</a></li>
          </ul>
        </div>
        <div class="footer-col">
          <h4>Misc</h4>
          <ul>
            <li><a href="nigam36.html">examples</a></li>
            <li><a href="nigam43.html">Robotic & AI</a></li>
            <li><a href="nigam44.html">Future of AI</a></li>
            <li><a href="nigam47.html">Scope of AI</a></li>
            <li><a href="nigam81.html">open AI&ChatGPT</a></li>
          </ul>
        </div>
        <div class="footer-col">
          <h4>follow us</h4>
          <div class="social-links">
            <a href="https://www.facebook.com/nigam.mishra.710?mibextid=9R9pXO"><i class="fa-brands fa-facebook-f"></i></a>
            <a href="https://twitter.com/MishraNugam?s=09"><i class="fa-brands fa-twitter"></i></a>
            <a href="https://instagram.com/mr_nigam_8199?igshid=MXNzeGI3bmZ6b3M3NQ=="><i class="fa-brands fa-instagram"></i></a>
            <a href=""><i class="fa-brands fa-youtube"></i></a>
          </div>
          <a href="contact1.html"><img src="photo/logo2.jpg" style="height: 100px;width: 100px;"></a>
        </div>
      </div>
    </footer>
  </body>
  </div>
  

  </div>
  <br><br><div class="mobilemenu" style="clear:both">
  </div></div>